{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import sounddevice as sd\n",
    "import json\n",
    "\n",
    "import jax\n",
    "from jax import numpy as jnp, Array\n",
    "from jax.typing import ArrayLike\n",
    "import flax\n",
    "from flax import linen as nn\n",
    "from flax.core import FrozenDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('musicnet/musicnet_metadata.csv')\n",
    "labels = metadata['ensemble'].values\n",
    "labels_to_nums = {label: i for i, label in enumerate(sorted(set(labels)))}\n",
    "nums_to_labels = {i: label for label, i in labels_to_nums.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "  @nn.compact\n",
    "  def __call__(self, x: ArrayLike, training: bool) -> Array:\n",
    "    x = (nn.Conv(features=8, kernel_size=(3, 3), use_bias=False))(x)\n",
    "    x = nn.BatchNorm(use_running_average=not training)(x)\n",
    "    x = nn.relu(x)\n",
    "    x = nn.max_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "\n",
    "    x = nn.Conv(features=8, kernel_size=(3, 3), use_bias=False)(x)\n",
    "    x = nn.BatchNorm(use_running_average=not training)(x)\n",
    "    x = nn.relu(x)\n",
    "    x = nn.max_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "\n",
    "    x = nn.Conv(features=8, kernel_size=(3, 3), use_bias=False)(x)\n",
    "    x = nn.BatchNorm(use_running_average=not training)(x)\n",
    "    x = nn.relu(x)\n",
    "    x = nn.max_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "\n",
    "    x = x.reshape((x.shape[0], -1))\n",
    "    \n",
    "    x = nn.Dense(features=128)(x)\n",
    "    x = nn.relu(x)\n",
    "\n",
    "    x = nn.Dense(features=64)(x)\n",
    "    x = nn.relu(x)\n",
    "\n",
    "    x = nn.Dense(features=21)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_load_path = 'checkpoints/cnn-params.json'\n",
    "with open(params_load_path, 'r') as f:\n",
    "  loaded_params_dict = json.load(f)\n",
    "\n",
    "params = FrozenDict({\n",
    "  k1: FrozenDict({\n",
    "    k2: jnp.array(v2) for k2, v2 in v1.items()\n",
    "  }) for k1, v1 in loaded_params_dict.items()\n",
    "})\n",
    "\n",
    "batch_stats_load_path = 'checkpoints/cnn-batch_stats.json'\n",
    "with open(batch_stats_load_path, 'r') as f:\n",
    "  loaded_batch_stats_dict = json.load(f)\n",
    "\n",
    "batch_stats = FrozenDict({\n",
    "  k1: FrozenDict({\n",
    "    k2: jnp.array(v2) for k2, v2 in v1.items()\n",
    "  }) for k1, v1 in loaded_batch_stats_dict.items()\n",
    "})\n",
    "\n",
    "model = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mels = 512\n",
    "\n",
    "def wav_to_mel_spec(path: str) -> np.ndarray:\n",
    "  y, sr = librosa.load(path)\n",
    "  spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
    "  return np.abs(librosa.amplitude_to_db(spec, ref=np.max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = glob('musicnet/musicnet/*/*.wav')\n",
    "data = jnp.array([wav_to_mel_spec(path)[:, :512].reshape(512, 512, 1) for path in data_files[:4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model.apply({\n",
    "  'params': params,\n",
    "  'batch_stats': batch_stats,\n",
    "}, x=data, training=False)\n",
    "\n",
    "[nums_to_labels[int(i)] for i in jnp.argmax(logits, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(data_files[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = 60\n",
    "sr = 22050\n",
    "y = sd.rec(int(duration * sr), samplerate=sr, channels=1, dtype=np.float32)\n",
    "sd.wait()\n",
    "y = y.reshape(len(y))\n",
    "spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
    "x = np.abs(librosa.amplitude_to_db(spec, ref=np.max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x[:, 512:1024].reshape(1, 512, 512, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = model.apply({\n",
    "  'params': params,\n",
    "  'batch_stats': batch_stats,\n",
    "}, x=data, training=False)\n",
    "\n",
    "nums_to_labels[int(jnp.argmax(logit, axis=1)[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.play(y, sr)\n",
    "sd.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
