{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import jax\n",
    "from jax import numpy as jnp, jit, grad\n",
    "import flax\n",
    "from flax import linen as nn\n",
    "from flax.training.train_state import TrainState\n",
    "import optax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preproscessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('musicnet_metadata.csv')\n",
    "train_data_files = glob('musicnet/musicnet/train_data/*.wav')\n",
    "test_data_files = glob('musicnet/musicnet/test_data/*.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wav_to_mel_spec(path):\n",
    "  y, sr = librosa.load(path)\n",
    "  spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=512)\n",
    "  return np.abs(librosa.amplitude_to_db(spec, ref=np.max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [wav_to_mel_spec(path) for path in train_data_files]\n",
    "test_data = [wav_to_mel_spec(path) for path in test_data_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_ids = [int(path[-8:-4]) for path in train_data_files]\n",
    "test_data_ids = [int(path[-8:-4]) for path in test_data_files]\n",
    "\n",
    "train_labels = [metadata[metadata['id'] == i]['ensemble'].values[0] for i in train_data_ids]\n",
    "test_labels = [metadata[metadata['id'] == i]['ensemble'].values[0] for i in test_data_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_to_nums = {label: i for i, label in enumerate(set(train_labels))}\n",
    "nums_to_labels = {i: label for label, i in labels_to_nums.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array([x[:, :1024].reshape(512, 1024, 1) for x in train_data], np.float32)\n",
    "x_test = np.array([x[:, :1024].reshape(512, 1024, 1) for x in test_data], np.float32)\n",
    "y_train = np.array([labels_to_nums[label] for label in train_labels], np.int32)\n",
    "y_test = np.array([labels_to_nums[label] for label in test_labels], np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "\n",
    "batch_size = 10\n",
    "train_ds = train_ds.shuffle(buffer_size=len(x_train)).batch(batch_size)\n",
    "test_ds = test_ds.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "  @nn.compact\n",
    "  def __call__(self, x):\n",
    "    x = nn.Conv(features=32, kernel_size=(3, 3))(x)\n",
    "    x = nn.relu(x)\n",
    "    x = nn.max_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "\n",
    "    x = nn.Conv(features=16, kernel_size=(3, 3))(x)\n",
    "    x = nn.relu(x)\n",
    "    x = nn.max_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "\n",
    "    x = nn.Conv(features=8, kernel_size=(3, 3))(x)\n",
    "    x = nn.relu(x)\n",
    "    x = nn.max_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "\n",
    "    x = x.reshape((x.shape[0], -1))\n",
    "    \n",
    "    x = nn.Dense(features=128)(x)\n",
    "    x = nn.relu(x)\n",
    "    x = nn.Dense(features=21)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_state(model, rng, learning_rate):\n",
    "  params = model.init(rng, jnp.ones((1, *x_train.shape[1:])))['params']\n",
    "  tx = optax.adam(learning_rate)\n",
    "  return TrainState.create(apply_fn=model.apply, params=params, tx=tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def train_step(state, batch):\n",
    "  def loss_fn(params):\n",
    "    logits = state.apply_fn({'params': params}, batch[0])\n",
    "    return optax.softmax_cross_entropy_with_integer_labels(logits=logits, labels=batch[1]).mean()\n",
    "  \n",
    "  grad_fn = grad(loss_fn)\n",
    "  return state.apply_gradients(grads=grad_fn(state.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def compute_metrics(state, batch):\n",
    "  logits = state.apply_fn({'params': state.params}, batch[0])\n",
    "  loss = optax.softmax_cross_entropy_with_integer_labels(logits=logits, labels=batch[1]).mean()\n",
    "  preds = jnp.argmax(logits, axis=1)\n",
    "  acc = jnp.mean(preds == batch[1])\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "flax_model = CNN()\n",
    "state = create_train_state(flax_model, jax.random.PRNGKey(0), learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] train acc: 0.03437500074505806, test acc: 0.10000000149011612\n",
      "[epoch 2] train acc: 0.4781250059604645, test acc: 0.30000001192092896\n",
      "[epoch 3] train acc: 0.4781250059604645, test acc: 0.30000001192092896\n",
      "[epoch 4] train acc: 0.4937499761581421, test acc: 0.30000001192092896\n",
      "[epoch 5] train acc: 0.49062496423721313, test acc: 0.30000001192092896\n",
      "[epoch 6] train acc: 0.5312500596046448, test acc: 0.30000001192092896\n",
      "[epoch 7] train acc: 0.5750000476837158, test acc: 0.30000001192092896\n",
      "[epoch 8] train acc: 0.546875, test acc: 0.4000000059604645\n",
      "[epoch 9] train acc: 0.5375000238418579, test acc: 0.4000000059604645\n",
      "[epoch 10] train acc: 0.6124999523162842, test acc: 0.30000001192092896\n",
      "[epoch 11] train acc: 0.640625, test acc: 0.30000001192092896\n",
      "[epoch 12] train acc: 0.6312500238418579, test acc: 0.30000001192092896\n",
      "[epoch 13] train acc: 0.637499988079071, test acc: 0.30000001192092896\n",
      "[epoch 14] train acc: 0.6968749761581421, test acc: 0.4000000059604645\n",
      "[epoch 15] train acc: 0.6968749761581421, test acc: 0.30000001192092896\n",
      "[epoch 16] train acc: 0.7281249761581421, test acc: 0.4000000059604645\n",
      "[epoch 17] train acc: 0.7374998927116394, test acc: 0.4000000059604645\n",
      "[epoch 18] train acc: 0.7718749046325684, test acc: 0.4000000059604645\n",
      "[epoch 19] train acc: 0.793749988079071, test acc: 0.5\n",
      "[epoch 20] train acc: 0.8156249523162842, test acc: 0.5\n",
      "[epoch 21] train acc: 0.8312498331069946, test acc: 0.4000000059604645\n",
      "[epoch 22] train acc: 0.8968748450279236, test acc: 0.5\n",
      "[epoch 23] train acc: 0.9312499165534973, test acc: 0.6000000238418579\n",
      "[epoch 24] train acc: 0.9593749046325684, test acc: 0.699999988079071\n",
      "[epoch 25] train acc: 0.9624999165534973, test acc: 0.699999988079071\n",
      "[epoch 26] train acc: 0.9749999046325684, test acc: 0.699999988079071\n",
      "[epoch 27] train acc: 0.9906249642372131, test acc: 0.699999988079071\n",
      "[epoch 28] train acc: 0.9937499761581421, test acc: 0.6000000238418579\n",
      "[epoch 29] train acc: 0.9906249642372131, test acc: 0.699999988079071\n",
      "[epoch 30] train acc: 0.996874988079071, test acc: 0.6000000238418579\n",
      "[epoch 31] train acc: 1.0, test acc: 0.699999988079071\n",
      "[epoch 32] train acc: 1.0, test acc: 0.6000000238418579\n",
      "[epoch 33] train acc: 1.0, test acc: 0.699999988079071\n",
      "[epoch 34] train acc: 1.0, test acc: 0.699999988079071\n",
      "[epoch 35] train acc: 1.0, test acc: 0.699999988079071\n",
      "[epoch 36] train acc: 1.0, test acc: 0.699999988079071\n",
      "[epoch 37] train acc: 1.0, test acc: 0.699999988079071\n",
      "[epoch 38] train acc: 1.0, test acc: 0.699999988079071\n",
      "[epoch 39] train acc: 1.0, test acc: 0.699999988079071\n",
      "[epoch 40] train acc: 1.0, test acc: 0.699999988079071\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 40\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  for batch in train_ds.as_numpy_iterator():\n",
    "    state = train_step(state, batch)\n",
    "  \n",
    "  train_acc_list = []\n",
    "  test_acc_list = []\n",
    "\n",
    "  for batch in train_ds.as_numpy_iterator():\n",
    "    acc = compute_metrics(state, batch)\n",
    "    train_acc_list.append(acc)\n",
    "\n",
    "  for batch in test_ds.as_numpy_iterator():\n",
    "    acc = compute_metrics(state, batch)\n",
    "    test_acc_list.append(acc)\n",
    "  \n",
    "  train_acc = sum(train_acc_list) / len(train_acc_list)\n",
    "  test_acc = sum(test_acc_list) / len(test_acc_list)\n",
    "\n",
    "  print(f'[epoch {epoch + 1}] train acc: {train_acc}, test acc: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
