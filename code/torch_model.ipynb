{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date Preproscessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('musicnet_metadata.csv')\n",
    "train_data_files = glob('musicnet/musicnet/train_data/*.wav')\n",
    "test_data_files = glob('musicnet/musicnet/test_data/*.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wav_to_mel_spec(path):\n",
    "  y, sr = librosa.load(path)\n",
    "  S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=512)\n",
    "  return np.abs(librosa.amplitude_to_db(S, ref=np.max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [wav_to_mel_spec(path) for path in train_data_files]\n",
    "test_data = [wav_to_mel_spec(path) for path in test_data_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_ids = [int(path[-8:-4]) for path in train_data_files]\n",
    "test_data_ids = [int(path[-8:-4]) for path in test_data_files]\n",
    "\n",
    "train_labels = [metadata[metadata['id'] == i]['ensemble'].values[0] for i in train_data_ids]\n",
    "test_labels = [metadata[metadata['id'] == i]['ensemble'].values[0] for i in test_data_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_to_nums = {label: i for i, label in enumerate(set(train_labels))}\n",
    "nums_to_labels = {i: label for label, i in labels_to_nums.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array([x[:, :1024].reshape(1, 512, 1024) for x in train_data])\n",
    "y_train = np.array([labels_to_nums[label] for label in train_labels])\n",
    "\n",
    "x_test = np.array([x[:, :1024].reshape(1, 512, 1024) for x in test_data])\n",
    "y_test = np.array([labels_to_nums[label] for label in test_labels])\n",
    "\n",
    "x_train_tensor = torch.from_numpy(x_train).float()\n",
    "y_train_tensor = torch.from_numpy(y_train).long()\n",
    "\n",
    "x_test_tensor = torch.from_numpy(x_test).float()\n",
    "y_test_tensor = torch.from_numpy(y_test).long()\n",
    "\n",
    "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(x_test_tensor, y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Net, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(1, 32, 3)\n",
    "    self.pool = nn.MaxPool2d(2, 2)\n",
    "    self.conv2 = nn.Conv2d(32, 16, 3)\n",
    "    self.conv3 = nn.Conv2d(16, 8, 3)\n",
    "    self.fc1 = nn.Linear(62496, 128)\n",
    "    self.fc2 = nn.Linear(128, 21)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.pool(F.relu(self.conv1(x)))\n",
    "    x = self.pool(F.relu(self.conv2(x)))\n",
    "    x = self.pool(F.relu(self.conv3(x)))\n",
    "    x = torch.flatten(x, 1)\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.relu(self.fc2(x))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(data_loader):\n",
    "  loss_sum = 0.0\n",
    "  num_correct = 0\n",
    "  num_total = 0\n",
    "  \n",
    "  net.eval()\n",
    "  with torch.no_grad():\n",
    "    for inputs, labels in data_loader:\n",
    "      outputs = net(inputs)\n",
    "      loss = loss_fn(outputs, labels)\n",
    "      loss_sum += loss.item()\n",
    "      _, predicted = torch.max(outputs, 1)\n",
    "      num_correct += (predicted == labels).sum().item()\n",
    "      num_total += labels.size(0)\n",
    "\n",
    "  return loss_sum / len(data_loader), num_correct / num_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 train loss: 2.9938, train accuracy: 0.4031\n",
      "epoch: 1 test loss: 3.0313, test accuracy: 0.0000\n",
      "epoch: 2 train loss: 2.7395, train accuracy: 0.5250\n",
      "epoch: 2 test loss: 2.8064, test accuracy: 0.3000\n",
      "epoch: 3 train loss: 1.9712, train accuracy: 0.5469\n",
      "epoch: 3 test loss: 2.4754, test accuracy: 0.4000\n",
      "epoch: 4 train loss: 1.9434, train accuracy: 0.6375\n",
      "epoch: 4 test loss: 2.3217, test accuracy: 0.4000\n",
      "epoch: 5 train loss: 2.9351, train accuracy: 0.4781\n",
      "epoch: 5 test loss: 2.9800, test accuracy: 0.3000\n",
      "epoch: 6 train loss: 2.9437, train accuracy: 0.4781\n",
      "epoch: 6 test loss: 2.9742, test accuracy: 0.3000\n",
      "epoch: 7 train loss: 2.3648, train accuracy: 0.4781\n",
      "epoch: 7 test loss: 2.7332, test accuracy: 0.3000\n",
      "epoch: 8 train loss: 1.7140, train accuracy: 0.6344\n",
      "epoch: 8 test loss: 2.4362, test accuracy: 0.4000\n",
      "epoch: 9 train loss: 1.4123, train accuracy: 0.6719\n",
      "epoch: 9 test loss: 1.8260, test accuracy: 0.6000\n",
      "epoch: 10 train loss: 1.0764, train accuracy: 0.7406\n",
      "epoch: 10 test loss: 2.3628, test accuracy: 0.6000\n",
      "epoch: 11 train loss: 2.5819, train accuracy: 0.5813\n",
      "epoch: 11 test loss: 2.8228, test accuracy: 0.2000\n",
      "epoch: 12 train loss: 1.7418, train accuracy: 0.6781\n",
      "epoch: 12 test loss: 2.2937, test accuracy: 0.4000\n",
      "epoch: 13 train loss: 1.2104, train accuracy: 0.7750\n",
      "epoch: 13 test loss: 2.8974, test accuracy: 0.5000\n",
      "epoch: 14 train loss: 0.8506, train accuracy: 0.8000\n",
      "epoch: 14 test loss: 3.0784, test accuracy: 0.5000\n",
      "epoch: 15 train loss: 0.6854, train accuracy: 0.8156\n",
      "epoch: 15 test loss: 1.4643, test accuracy: 0.6000\n",
      "epoch: 16 train loss: 0.6101, train accuracy: 0.8219\n",
      "epoch: 16 test loss: 2.0637, test accuracy: 0.5000\n",
      "epoch: 17 train loss: 0.5641, train accuracy: 0.8250\n",
      "epoch: 17 test loss: 1.7906, test accuracy: 0.5000\n",
      "epoch: 18 train loss: 0.5438, train accuracy: 0.8281\n",
      "epoch: 18 test loss: 1.8610, test accuracy: 0.5000\n",
      "epoch: 19 train loss: 0.5324, train accuracy: 0.8344\n",
      "epoch: 19 test loss: 1.8782, test accuracy: 0.5000\n",
      "epoch: 20 train loss: 0.5173, train accuracy: 0.8344\n",
      "epoch: 20 test loss: 1.6936, test accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  net.train()\n",
    "  for inputs, labels in train_loader:\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(inputs)\n",
    "    loss = loss_fn(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "  net.eval()\n",
    "  with torch.no_grad():\n",
    "    train_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    for inputs, labels in train_loader:\n",
    "      outputs = net(inputs)\n",
    "      loss = loss_fn(outputs, labels)\n",
    "      train_loss += loss.item()\n",
    "      _, predicted = torch.max(outputs, 1)\n",
    "      total_train += labels.size(0)\n",
    "      correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "    test_loss = 0.0\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "    for inputs, labels in test_loader:\n",
    "      outputs = net(inputs)\n",
    "      loss = loss_fn(outputs, labels)\n",
    "      test_loss += loss.item()\n",
    "      _, predicted = torch.max(outputs, 1)\n",
    "      total_test += labels.size(0)\n",
    "      correct_test += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    train_acc = correct_train / total_train\n",
    "    print('epoch:', epoch + 1, 'train loss: {:.4f}, train accuracy: {:.4f}'.format(avg_train_loss, train_acc))\n",
    "\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    test_acc = correct_test / total_test\n",
    "    print('epoch:', epoch + 1, 'test loss: {:.4f}, test accuracy: {:.4f}'.format(avg_test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
