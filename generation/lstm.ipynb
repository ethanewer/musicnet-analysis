{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "import librosa\n",
    "import librosa.display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import Image, Audio\n",
    "import music21 as m21\n",
    "import json\n",
    "import functools\n",
    "\n",
    "import jax\n",
    "from jax import numpy as jnp, jit, grad, Array\n",
    "from jax.typing import ArrayLike\n",
    "import flax\n",
    "from flax import linen as nn\n",
    "from flax.training import train_state\n",
    "from flax.core import FrozenDict\n",
    "import optax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preproscessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = glob('musicnet/musicnet_midis/musicnet_midis/Bach/*.mid')\n",
    "midi_data = []\n",
    "for path in data_files:\n",
    "  try:\n",
    "    midi_data.append(m21.converter.parse(path))\n",
    "  except Exception:\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_notes(files):\n",
    "  notes = []\n",
    "  pick = None\n",
    "  for f in files:\n",
    "    piece = m21.instrument.partitionByInstrument(f)\n",
    "    for part in piece.parts:\n",
    "      pick = part.recurse()\n",
    "      for element in pick:\n",
    "        if isinstance(element, m21.note.Note):\n",
    "          notes.append(str(element.pitch))\n",
    "        elif isinstance(element, m21.chord.Chord):\n",
    "          notes.append(','.join(str(n) for n in element.normalOrder))\n",
    "  return notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = extract_notes(midi_data)\n",
    "\n",
    "num_unique_notes = len(set(notes))\n",
    "\n",
    "notes_to_nums = {note: i for i, note in enumerate(sorted(set(notes)))}\n",
    "nums_to_notes = {i: note for note, i in notes_to_nums.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_len = 64\n",
    "\n",
    "features = []\n",
    "targets = []\n",
    "\n",
    "for i in range(len(notes) - sample_len):\n",
    "  features.append([notes_to_nums[n] for n in notes[i:i + sample_len]])\n",
    "  targets.append(notes_to_nums[notes[i + sample_len]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_full = np.array(features, np.float32).reshape(len(features), sample_len, 1) / num_unique_notes\n",
    "y_full = np.array(targets, np.int32)\n",
    "\n",
    "x_train, x_seed, y_train, y_seed = train_test_split(x_full, y_full, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_seed, y_seed))\n",
    "\n",
    "batch_size = 16\n",
    "train_ds = train_ds.shuffle(buffer_size=len(x_seed)).batch(batch_size)\n",
    "test_ds = test_ds.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "  def setup(self) -> None:\n",
    "    lstm_layer = nn.scan(\n",
    "      nn.OptimizedLSTMCell,\n",
    "      variable_broadcast='params',\n",
    "      in_axes=1,\n",
    "      out_axes=1,\n",
    "      split_rngs={'params': False})\n",
    "    \n",
    "    self.lstm1 = lstm_layer(128)\n",
    "    self.lstm2 = lstm_layer(64)\n",
    "    self.dense1 = nn.Dense(256)\n",
    "    self.dense2 = nn.Dense(num_unique_notes)\n",
    "  \n",
    "  @nn.remat\n",
    "  def __call__(self, x: ArrayLike) -> Array:\n",
    "    carry, hidden = self.lstm1.initialize_carry(jax.random.PRNGKey(0), x[:, 0].shape)\n",
    "    (carry, hidden), x = self.lstm1((carry, hidden), x)\n",
    "\n",
    "    carry, hidden = self.lstm2.initialize_carry(jax.random.PRNGKey(1), x[:, 0].shape)\n",
    "    (carry, hidden), x = self.lstm2((carry, hidden), x)\n",
    "\n",
    "    x = x[:, -1]\n",
    "\n",
    "    x = self.dense1(x)\n",
    "    x = self.dense2(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainState = train_state.TrainState\n",
    "\n",
    "def create_train_state(model: LSTM, rng_key: Array, learning_rate: float) -> TrainState:\n",
    "  params = model.init(rng_key, x=x_train[:1])['params']\n",
    "  tx = optax.adam(learning_rate=learning_rate)\n",
    "  return train_state.TrainState.create(apply_fn=model.apply, params=params, tx=tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_state(model: LSTM, learning_rate: float, params_path: str) -> TrainState:\n",
    "  with open(params_path, 'r') as f:\n",
    "    params_dict = json.load(f)\n",
    "  \n",
    "  def freeze_dict(unfrozen_dict: dict[any]) -> FrozenDict[any]:\n",
    "    frozen_dict = {}\n",
    "    for k, v in unfrozen_dict.items():\n",
    "      if isinstance(v, dict):\n",
    "        frozen_dict[k] = freeze_dict(v)\n",
    "      else:\n",
    "        frozen_dict[k] = jnp.array(v)\n",
    "    return FrozenDict(frozen_dict) \n",
    "\n",
    "  params = freeze_dict(params_dict)\n",
    "  tx = optax.adam(learning_rate=learning_rate)\n",
    "  return train_state.TrainState.create(apply_fn=model.apply, params=params, tx=tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def train_step(state: TrainState, batch: tuple[ArrayLike, ArrayLike]) -> TrainState:\n",
    "\n",
    "  def loss_fn(params: FrozenDict) -> Array:\n",
    "    logits = LSTM().apply({'params': params}, x=batch[0])\n",
    "    loss = optax.softmax_cross_entropy_with_integer_labels(logits=logits, labels=batch[1]).mean()\n",
    "    return loss\n",
    "  \n",
    "  grad_fn = grad(loss_fn)\n",
    "  grads = grad_fn(state.params)\n",
    "  state = state.apply_gradients(grads=grads)\n",
    "  return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def accuracy(state: TrainState, batch: ArrayLike):\n",
    "  logits = state.apply_fn({'params': state.params}, x=batch[0])\n",
    "  preds = jnp.argmax(logits, axis=1)\n",
    "  acc = jnp.mean(preds == batch[1])\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM()\n",
    "state = create_train_state(model, jax.random.PRNGKey(0), learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  for batch in train_ds.as_numpy_iterator():\n",
    "    state = train_step(state, batch)\n",
    "  \n",
    "  train_acc_list = []\n",
    "  test_acc_list = []\n",
    "\n",
    "  for batch in train_ds.as_numpy_iterator():\n",
    "    acc = accuracy(state, batch)\n",
    "    train_acc_list.append(acc)\n",
    "\n",
    "  for batch in test_ds.as_numpy_iterator():\n",
    "    acc = accuracy(state, batch)\n",
    "    test_acc_list.append(acc)\n",
    "  \n",
    "  train_acc = sum(train_acc_list) / len(train_acc_list)\n",
    "  test_acc = sum(test_acc_list) / len(test_acc_list)\n",
    "\n",
    "  print(f'[epoch {epoch + 1}] train acc: {train_acc}, test acc: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unfreeze_dict(frozen_dict: FrozenDict[any]) -> dict[any]:\n",
    "  unfrozen_dict = {}\n",
    "  for k, v in frozen_dict.items():\n",
    "    if isinstance(v, FrozenDict) or isinstance(v, dict):\n",
    "      unfrozen_dict[k] = unfreeze_dict(v)\n",
    "    else:\n",
    "      unfrozen_dict[k] = v.tolist()\n",
    "  return unfrozen_dict\n",
    "\n",
    "params_save_path = 'checkpoints/lstm-params.json'\n",
    "params_dict = unfreeze_dict(state.params)\n",
    "with open(params_save_path, 'w') as f:\n",
    "  json.dump(params_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_melody(note_len: int) -> m21.stream.Stream:\n",
    "  rand_idx = np.random.randint(0, len(x_seed))\n",
    "  seed = x_seed[rand_idx:rand_idx + 1]\n",
    "  music = []\n",
    "  for i in range(note_len):\n",
    "    logits = state.apply_fn({'params': state.params}, x=seed)\n",
    "    pred = int(jnp.argmax(logits, axis=1)[0])\n",
    "    music.append(str(nums_to_notes[pred]))\n",
    "    seed = np.hstack((seed[:, 1:], [[[pred]]]))\n",
    "  \n",
    "  melody = []\n",
    "  offset = 0 \n",
    "  for x in music:\n",
    "    if ',' in x or x.isdigit():\n",
    "      chord_notes = [] \n",
    "      for y in x.split(','):\n",
    "        chord_notes.append(m21.note.Note(int(y)))\n",
    "        chord_snip = m21.chord.Chord(chord_notes)\n",
    "        chord_snip.offset = offset\n",
    "        melody.append(chord_snip)\n",
    "    else: \n",
    "      note_snip = m21.note.Note(x)\n",
    "      note_snip.offset = offset\n",
    "      melody.append(note_snip)\n",
    "    offset += 1\n",
    "\n",
    "  melody_midi = m21.stream.Stream(melody)   \n",
    "  return melody_midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melody = generate_melody(128)\n",
    "melody.write('midi', 'generated_music.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums_to_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
